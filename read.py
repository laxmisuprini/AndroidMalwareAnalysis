import numpy as np
import sys
import feature_extraction
from os import listdir
from os.path import isfile, join
import pandas as pd
import os

mypath = "/home/priya/Documents/mini_project/feature_vectors"
onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]
#print (onlyfiles)
#malware_set = np.loadtxt("data/drebin/sha256_family.csv", delimiter=",", skiprows=1, dtype=str)

for text_file in onlyfiles:
            sys.stdin = open("%s/%s" % (mypath, text_file))
            features = sys.stdin.readlines()
            #print (features)
            sample = feature_extraction.count_feature_set(features)
            #print (sample)
def read_dat():
    malware_set=pd.read_csv("sha256_family .csv")
    #print (os.getcwd())
    data_path = os.path.join(os.getcwd(), 'feature_vectors')
    #print (data_path)
    print('Found (' + str(len(malware_set.index)) + ') malware families in csv file.')  
    dataset_files_length = len(onlyfiles)
   # print('Found (' + str(dataset_files_length) + ') feature vector files to classify.')  
    malware_files=[]
    not_malware =[]
    # into malware sets and not malware sets
    
    for file in onlyfiles:
    	if file in (malware_set.values[:,0]):
    		malware_files.append(file)
    	else:
    	    not_malware.append(file)	
   # print (len(not_malware))

   # print (len(malware_files))

    x=[]
    y=[]

    for mf in malware_files:
    	with open(data_path + '/' + mf, 'r') as file:
    		file_content = file.read().splitlines()
    		sample = feature_extraction.count_feature_set(file_content)
    		x.append(sample)
    		y.append(1)

     
    for nf in not_malware:
    	with open(data_path + '/' +nf,'r') as file:
    		file_content = file.read().splitlines()
    		sample = feature_extraction.count_feature_set(file_content)
    		x.append(sample)
    		y.append(0)
    x=np.array(x)
    y=np.array(y)
    print (x[0])
   # print("\nFeatures & Labels arrays' shapes, respectively: " + str(x.shape), str(y.shape))
    return x,y		



'''def read(LOAD_DATA=False):
    if LOAD_DATA:
        print ("Previous data not loaded. Attempt to read data ...")
        mypath = "/home/priya/Documents/mini_project/feature_vectors"
        onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]

        print ("Reading csv file for ground truth ...")
        ground_truth = np.loadtxt("sha256_family.csv", delimiter=",", skiprows=1, dtype=str)
        # print ground_truth.shape
        # families = np.unique(ground_truth[:, 1])
        # print families
        # print len(families)

        print ("Reading positive and negative texts ...")
        pos = []
        neg = []
        for virus in onlyfiles:
            if virus in ground_truth[:, 0]:
                pos.append(virus)
            else:
                if len(neg) < 5560:
                    neg.append(virus)

        print ("Extracting features ...")
        x = []
        y = []
        for text_file in pos:
            sys.stdin = open("%s/%s" % (mypath, text_file))
            features = sys.stdin.readlines()
            sample = feature_extraction.count_feature_set(features)
            x.append(sample)
            y.append(1)

        for text_file in neg:
            sys.stdin = open("%s/%s" % (mypath, text_file))
            features = sys.stdin.readlines()
            sample = feature_extraction.count_feature_set(features)
            x.append(sample)
            y.append(0)

        print ("Data is read successfully:")
        x = np.array(x)
        y = np.array(y)
        print (x.shape, y.shape)

        print ("Saving data under data_numpy directory ...")
        np.save("data_numpy/x_all.npy", x)
        np.save("data_numpy/y_all.npy", y)

        return x, y
    else:
        print ("Loading previous data ...")
        x_ = np.load("data_numpy/x_all.npy")
        y_ = np.load("data_numpy/y_all.npy")
        print (x_.shape, y_.shape)
        # print x == x_, y == y_
        return x_, y_
'''